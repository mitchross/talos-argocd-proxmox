# Global settings for the Argo CD chart
global:
  # Ingress is disabled; external access is managed via HTTPRoute
  ingress:
    enabled: false
# ConfigMaps and feature flags
configs:
  params:
    server.insecure: "true"
    # Performance: increase parallel status checks (default 20, ~1 per 20 apps)
    controller.status.processors: "50"
    # Performance: increase concurrent sync operations (default 10)
    controller.operation.processors: "25"
    # Performance: limit concurrent manifest generations to prevent OOM
    reposerver.parallelism.limit: "5"
    # Performance: increase repo-server timeout for large Helm charts like prometheus-stack
    controller.repo.server.timeout.seconds: "300"
  cm:
    url: "https://argocd.vanillax.me"
    kustomize.buildOptions: "--enable-helm"
    # Performance: add jitter to prevent all 60+ apps reconciling simultaneously
    timeout.reconciliation: "60s"
    timeout.reconciliation.jitter: "30s"
    # Force cache invalidation periodically so manual Sync actually re-fetches from git
    timeout.hard.reconciliation: "60s"
    # Ignore Gateway API HTTPRoute parentRefs normalization
    resource.customizations.ignoreDifferences.gateway.networking.k8s.io_HTTPRoute: |
      jqPathExpressions:
      - '.spec.parentRefs[]? | select(.group == null or .kind == null)'
      jsonPointers:
      - /spec/parentRefs
    # Enable Application health check for app-of-apps sync waves
    # This was removed in ArgoCD 1.8 but is needed for sync waves to work properly
    resource.customizations.health.argoproj.io_Application: |
      hs = {}
      hs.status = "Progressing"
      hs.message = ""
      if obj.status ~= nil then
        if obj.status.health ~= nil then
          hs.status = obj.status.health.status
          if obj.status.health.message ~= nil then
            hs.message = obj.status.health.message
          end
        end
      end
      return hs
    # Custom health checks for VolSync resources
    resource.customizations.health.volsync.backube_ReplicationSource: |
      hs = {}
      if obj.status ~= nil then
        if obj.status.lastSyncTime ~= nil then
          hs.status = "Healthy"
          hs.message = "Last sync: " .. obj.status.lastSyncTime
          return hs
        end
      end
      hs.status = "Progressing"
      hs.message = "Waiting for first sync"
      return hs
    resource.customizations.health.volsync.backube_ReplicationDestination: |
      hs = {}
      if obj.status ~= nil and obj.status.latestImage ~= nil then
        hs.status = "Healthy"
        hs.message = "Ready for restore"
        return hs
      end
      hs.status = "Progressing"
      hs.message = "Initializing"
      return hs
# Argo CD server settings
server:
  replicas: 2
  ingress:
    enabled: false
  env:
    - name: ARGOCD_GRPC_MAX_SIZE_MB
      value: "200"
  metrics:
    enabled: true
    serviceMonitor:
      enabled: true
      additionalLabels:
        release: kube-prometheus-stack
  resources:
    requests:
      cpu: 500m
      memory: 512Mi
    limits:
      cpu: 2000m
      memory: 2Gi
# ApplicationSet controller settings
applicationSet:
  enabled: true
  metrics:
    enabled: true
    serviceMonitor:
      enabled: true
      additionalLabels:
        release: kube-prometheus-stack
  resources:
    requests:
      cpu: 250m
      memory: 256Mi
    limits:
      cpu: 1000m
      memory: 1Gi
# High Availability setup
ha:
  enabled: true
  redis:
    resources:
      requests:
        cpu: 100m
        memory: 128Mi
      limits:
        cpu: 500m
        memory: 512Mi
# Argo CD controller settings
controller:
  env:
    # Performance: increase K8s API client throughput
    - name: ARGOCD_K8S_CLIENT_QPS
      value: "50"
    - name: ARGOCD_K8S_CLIENT_BURST
      value: "100"
    # Performance: split large app trees across Redis keys
    - name: ARGOCD_APPLICATION_TREE_SHARD_SIZE
      value: "100"
  metrics:
    enabled: true
    applicationLabels:
      enabled: true
    serviceMonitor:
      enabled: true
      additionalLabels:
        release: kube-prometheus-stack
  resources:
    requests:
      cpu: 1000m
      memory: 1Gi
    limits:
      cpu: 4000m
      memory: 4Gi
# Argo CD repo-server settings
repoServer:
  replicas: 2
  env:
    - name: ARGOCD_EXEC_TIMEOUT
      value: "3m"
  metrics:
    enabled: true
    serviceMonitor:
      enabled: true
      additionalLabels:
        release: kube-prometheus-stack
  resources:
    requests:
      cpu: 1000m
      memory: 1Gi
    limits:
      cpu: 4000m
      memory: 4Gi
# Dex is disabled; external authentication (e.g. SSO) is used
dex:
  enabled: false
notifications:
  enabled: true
  secret:
    create: true
  metrics:
    enabled: true
    serviceMonitor:
      enabled: true
      additionalLabels:
        release: kube-prometheus-stack
hpa:
  enabled: true
  minReplicas: 1
  maxReplicas: 5
  targetCPUUtilizationPercentage: 80
  targetMemoryUtilizationPercentage: 80
