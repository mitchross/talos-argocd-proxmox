apiVersion: batch/v1
kind: Job
metadata:
  name: comfyui-download-models
  namespace: comfyui
spec:
  ttlSecondsAfterFinished: 86400  # Auto-cleanup after 24h
  backoffLimit: 3
  template:
    metadata:
      labels:
        app: comfyui-model-downloader
    spec:
      restartPolicy: OnFailure
      containers:
      - name: downloader
        image: python:3.12-slim
        command:
        - bash
        - -c
        - |
          set -euo pipefail

          pip install -q huggingface_hub

          echo "=== Downloading Z-Image-Turbo (text-to-image) ==="
          echo "Source: Comfy-Org/z_image_turbo (ComfyUI-optimized checkpoint)"

          # Z-Image-Turbo diffusion model (~10GB AIO FP8 or ~20GB BF16)
          python -c "
          from huggingface_hub import hf_hub_download
          import os

          token = os.environ.get('HF_TOKEN', None)

          # Z-Image-Turbo AIO FP8 (self-contained, ~10.3GB, fits easily on 3090)
          print('Downloading Z-Image-Turbo AIO FP8...')
          hf_hub_download(
              repo_id='Comfy-Org/z_image_turbo',
              filename='z_image_turbo_aio_fp8.safetensors',
              local_dir='/models/ComfyUI/models/diffusion_models',
              local_dir_use_symlinks=False,
              token=token
          )
          print('Done: z_image_turbo_aio_fp8.safetensors')

          # FLUX VAE (shared, needed by Z-Image-Turbo)
          print('Downloading FLUX VAE (ae.safetensors)...')
          hf_hub_download(
              repo_id='black-forest-labs/FLUX.1-dev',
              filename='ae.safetensors',
              local_dir='/models/ComfyUI/models/vae',
              local_dir_use_symlinks=False,
              token=token
          )
          print('Done: ae.safetensors')
          "

          echo ""
          echo "=== Downloading Qwen-Image-Edit-2511 GGUF (image editing) ==="
          echo "Source: unsloth/Qwen-Image-Edit-2511-GGUF"

          python -c "
          from huggingface_hub import hf_hub_download
          import os

          token = os.environ.get('HF_TOKEN', None)

          # Qwen-Image-Edit-2511 GGUF FP8 (~10GB, best quality for 3090)
          print('Downloading Qwen-Image-Edit-2511 GGUF...')
          hf_hub_download(
              repo_id='unsloth/Qwen-Image-Edit-2511-GGUF',
              filename='Qwen-Image-Edit-2511-UD-Q4_K_XL.gguf',
              local_dir='/models/ComfyUI/models/diffusion_models',
              local_dir_use_symlinks=False,
              token=token
          )
          print('Done: Qwen-Image-Edit-2511 GGUF')

          # Qwen-Image-Edit Lightning LoRA (4-step distillation)
          print('Downloading Qwen-Image-Edit Lightning LoRA...')
          hf_hub_download(
              repo_id='lightx2v/Qwen-Image-Edit-2511-Lightning',
              filename='Qwen-Image-Edit-2511-Lightning.safetensors',
              local_dir='/models/ComfyUI/models/loras',
              local_dir_use_symlinks=False,
              token=token
          )
          print('Done: Lightning LoRA')
          "

          echo ""
          echo "=== Downloading CLIP text encoders ==="

          python -c "
          from huggingface_hub import hf_hub_download
          import os

          token = os.environ.get('HF_TOKEN', None)

          # CLIP-L (used by Z-Image-Turbo and FLUX workflows)
          print('Downloading clip_l.safetensors...')
          hf_hub_download(
              repo_id='comfyanonymous/flux_text_encoders',
              filename='clip_l.safetensors',
              local_dir='/models/ComfyUI/models/text_encoders',
              local_dir_use_symlinks=False,
              token=token
          )
          print('Done: clip_l.safetensors')

          # T5-XXL FP8 (used by Z-Image and FLUX, ~5GB)
          print('Downloading t5xxl_fp8_e4m3fn.safetensors...')
          hf_hub_download(
              repo_id='comfyanonymous/flux_text_encoders',
              filename='t5xxl_fp8_e4m3fn.safetensors',
              local_dir='/models/ComfyUI/models/text_encoders',
              local_dir_use_symlinks=False,
              token=token
          )
          print('Done: t5xxl_fp8_e4m3fn.safetensors')
          "

          echo ""
          echo "=== All downloads complete ==="
          ls -lhR /models/ComfyUI/models/diffusion_models/
          ls -lhR /models/ComfyUI/models/vae/
          ls -lhR /models/ComfyUI/models/text_encoders/
          ls -lhR /models/ComfyUI/models/loras/

        env:
        - name: HF_TOKEN
          valueFrom:
            secretKeyRef:
              name: comfyui-secrets
              key: HF_TOKEN
        resources:
          requests:
            cpu: "1"
            memory: "2Gi"
          limits:
            cpu: "4"
            memory: "4Gi"
        volumeMounts:
        - name: comfyui-storage
          mountPath: /models
      volumes:
      - name: comfyui-storage
        persistentVolumeClaim:
          claimName: comfyui-storage
