apiVersion: apps/v1
kind: Deployment
metadata:
  name: ollama-webui
  namespace: ollama-webui
spec:
  strategy:
    type: Recreate
  replicas: 1
  selector:
    matchLabels:
      app: ollama-webui
  template:
    metadata:
      labels:
        app: ollama-webui
    spec:
      runtimeClassName: nvidia
      nodeSelector:
        feature.node.kubernetes.io/pci-0300_10de.present: "true"
      tolerations:
        - key: "gpu"
          operator: "Equal"
          value: "true"
          effect: "NoSchedule"
      containers:
        - name: ollama-webui
          # renovate: datasource=docker depName=ghcr.io/open-webui/open-webui
          image: ghcr.io/open-webui/open-webui:latest@sha256:53a4d2fc8c7a7cc620cd18e6fe416ed9940f2db87fddf837e3aa55111bec6995
          imagePullPolicy: IfNotPresent
          ports:
            - containerPort: 8080
          resources:
            requests:
              cpu: 500m
              memory: 1000Mi
              ephemeral-storage: "30Gi" 
            limits:
              memory: 8000Mi
              ephemeral-storage: "40Gi" 
          envFrom:
            - configMapRef:
                name: ollama-webui-configmap
          volumeMounts:
            - name: data
              mountPath: /app/backend/data
          # Health probes disabled - backend model loading can take several minutes
      volumes:
        - name: data
          persistentVolumeClaim:
            claimName: ollama-webui-storage-pvc
